* use terra's GP regression for detrending, rather than legendre series sums.

> not terra's imple,entatio, but the scikit learn implementation seems pretty
> slow. This definitely could be a useful method though (just more complicated
> than necessary)

* make completeness maps (vs δ_inj, P_inj, P_EB, rms_biased)

> Done. We need ~4x better noise RMS across all LCs.
> Note (per discussion w/ Fei Dai) a better metric than RMS is CDPP over 6hrs.
> This is like roughly "pass a 6 hour window over LC. for all the points in
> each window, compute variance. Then compute the mean of the variances".

* check normalization is being done thru *DIVISION* by mean (not subtraction),
b/c division preservers relative fluxes..

> Done

* Possible to high/loss pass filter at ~<2x EB period? (Read Feigelson text & see)

> Butterworth filters are the idea, and they ruin transits (smoothing is too
> powerful, timescales too close -- the sinc(f) of a FT'd box function does not
> play well with Butterworth).

* Email Johan for his code -- more general fourier approach (more expensive
  too).

> Emailed. Tried implemented it too -- works shittily. But my implementation
> may have bugs.

* iteratively whiten via either:
    1. if next bst period is a harmonic of original signal, subtract off new
    legendre fit
    2. scipy.signal: genereate filters based on Fourier representation of LC,
    including all the harmonics, and pass them thru
> barebones implementation done. 

* Iteratively whiten out more frequencies. (Say ~few more) (Nb. this depends on
  whether there are strong periodicities in current redtrended residuals, or
  whether the spot-movement is "pseudo-periodic")

* on iterwhiten plots: add ylabel including iternum (like what's already in fname)
  also show npts & legendredeg on phased fit.

* cut out data within "0.5d regions" of gaps (defined by
    >0.5day space btwn points)
  -> nb. lcmath.find_lc_timegroups(fsaptimes, mingap=mingap) is most relevant.
  -> implement as trim_near_gaps. 
  (nb. does not require "stitching" to get full LC... you can do just over 
  quarters still)

* revise period bounds of iterative whitening to [0.05day, 5xP_EB]

* debug why inum never goes above 2
  > bug: badly formed bracket -> a sqrt was trying to do a negative number and
  nanning

* during iterative whiten, add f(t) filter with mid-level legendre series fit
  (to time-groups), then subsequent subtraction for >~10day trend removal. 

* clear out the TODOs and FIXMEs from the iterative whitening implementation.

* in phase, it does not make sense to limit by npts. It should be the the
  number of phases being folded over! e.g., even w/ 1k points, at a 0.5 day fold
  you have 40 phases. The number of phases should be the determining factor, not
  the number of points (will help with Q0 and Q17)

* revise legendredeg(npts) function... maybe allow sharper even w/ fewer pts, as
  long as within "safe" period bounds (<5x P_EB).

* Similarly, fine-tune the sigma clipping based on the actual RMS across a
    quarter. **If (once detrended+whitened) it's very small, we must allow
    bigger dips (w/out clipping them).**

* lcmath.find_lc_timegroups -- basically an implementation of astrokep's
 find_lightcurve_gaps, already done.

- hard cut on escaping once RMS<0.05% threshold.

* complete tests/assessment of how well iterative whitening looks like it's 
  working (see e.g., how far down you can push in the rms floor)
  (also note that many sharp features seem to fail)

* add find_dip with iterative whitening 

* in recovery, check correct periods, off by 1 orbit in time. (this is b/c 
  min time gets cut. Implement a workaround at some stage, e.g., after
  BLS!)

* reassess completeness (coarse level).
  Result: it's complete enough for ~4Re, ~4-80P_EB period CBPs. (like 50%)

Sun 26 Mar 2017 09:52:32 AM EDT

* Fix injrecovresult_analysis to open whatever pickles are there and use THOSE,
rather than go thru whatever random number seeds are necessary.

> implemented. But now make it a cmd line arg with parser.
> done. we're finally using argparse, and i got the chance to refactor
  run_inj_recov to be wayyy clearer.

Identify highest significance dips in search:
########## 

X compute CDPP 6hr.

> after reading Christiansen's 2012 and Jenkins 2010 (CDPP) description...
this is not worth the effort. They're using some kind of wavelet matched
filter approach, and describe CDPP as a thing that only really can be computed
*sticking to their exact pipeline approach*. better idea is to just stick with
the RMS. 

X make plot to compare success0 and success1 RMSs (once success1 has correct
injrecovresults)

> yes, iterative whitening did help (duh). previously (single iteration) ~20%
of EBs had biased RMS less than 1e-3. with iterative withening, it's ~70%.

* get BLS depth (to compute depth/RMS)

* log recovered BLS depth in the csv files too

* plot: (recovered depth / injected depth) vs RMS (or whatever quantity).

* why do we have negative transit depths recovered?
> because BLS can find them. In a smaller number of cases (~10 of the ~540),
the whitening subtracts the planet signal (notably if it's very big). But the
point is that BLS has no prior for wanting positive depth transits. So 75 of
540 injection recovery tests wind up with NEGATIVE depths (mostly because of
stellar variability producing some kind of coherent signal in the periodogram).
It seems like it would be smarter to have some prior to avoid this.
Like "if the BLS depth for this proposed period is negative... downweight the
power of this period!!"
(Note e.g., the case dipsearchplot/inj/10090246_sapdipsearch_inj_0.00125.png:
primary period gives such a negative depth (i.e. a brightening). But there the
4th period gives the correct dip)

* does the 4th period get the correct recovered depth?
> yes. nthbestperiod gets serialdict, which contains the depths.

* in periodbase/kbls.py: add condition to ignore peaks that give BRIGHTENINGS
(rather than dimmings), i.e. get nbestpeaks that are POSITIVE.
> no, not in kbls.py. Reason: we need this to be happening in serial pfinder.
Like, the nbestperiods can only be selected based off the full periodogram (not
the depth info), because we don't know the depths for the nbestperiods (because
`eebls` only gives us the depths across frequency chunks).

This can be easily cut in post-processing -- just ignore anything with negative
depth -- but the issue is that we then aren't getting the full nbestpeaks for
each star (we'd be getting a few less -- like 15% less, since the problem is
~70 out of 500).

That's boarderline.

So to solve:
  * take e.g., 10 nbestperiods from parallel_pfind, and go thru them serially
  discarding anything that gives negative depths. Lets you go deeper into the
  periodogram

> done.

* bugfix:
(sci) luke@crispy:~/Dropbox/proj/cbp/src$ Traceback (most recent call last):
  File "run_inj_recov.py", line 522, in <module>
    injrecov_test1(103, stage='dipsearch', inj=True, ds=True, whitened=True)
  File "run_inj_recov.py", line 438, in injrecov_test1
    allq = ir.find_dips(lcd, allq, method='bls')
  File "/home/luke/Dropbox/proj/cbp/src/inj_recov.py", line 1930, in find_dips
    φ_egr = φ_bin[egrbinind]
IndexError: index 393 is out of bounds for axis 0 with size 392

[1]+  Exit 1                  python run_inj_recov.py > LOGS/completeness_test_170320_5.txt

Mon 27 Mar 2017 09:20:33 AM EDT

* after runs are complete, parse LOGS for LOGERRORs, e.g.,
      LOGERROR('ingbinind from eebls.f shorter than it should be.')
      LOGERROR('Hard-setting ingress and egress phases.')
  (that bug that I hard-coded a hacky-exception for, because I don't understand
  it)
  > put it to summary.txt (like: "there were X logerrors: (and list all of em)"

* refactor (e.g., on a new git branch) to take out pieces of code that are not
  and will not be used any more.
  -> tag current version as v0.1

* make injection actually optional in main (so that you can just run whitening
  and dipfinding search over all the KEBC stars)

*  fix retrieve_next_lc logic for repeats to work (in the style of: you have
the pickles, now you want the plots that you messed up earlier) 
        lcd, lcflag = ir.retrieve_next_lc()

* fix the order of dips in dipsearchplot to be correct...
  also fix the ylims
  also fix the dashed red lines shown on periodogram

Thu 30 Mar 2017 11:06:36 AM EDT

* turn ur existing completeness map data into a "heatmap" (like shade in where
  you can detect things, and where you can't). then show ur candidates on that
  map.

* add baseline, SNR_inj_pf, SNR_rec_pf to result csvs

* Write something that lets you regenerate, from pkls:
  X injrecov summary csv files
  > LOL i already did this. that's the `-p` option.
  X recov summary csv files
  > added option for this

* Sort discovered candidates by depth/RMS * sqrt(obs baseline)... or something else?
  * Make plots to see how clean this is (scatter, then completeness maps)

* debug:
(sci) luke@crispy:~/Dropbox/proj/cbp/src$ Traceback (most recent call last):
File "run_the_machine.py", line 146, in recov irp.whitenedplot_6row(lcd,
ap='sap', stage=stage, inj=inj) File
"/home/luke/Dropbox/proj/cbp/src/inj_recov_plots.py", line 549, in
whitenedplot_6row f.savefig(savedir+plotname, dpi=300) File
"/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/figure.py",
line 1565, in savefig self.canvas.print_figure(*args, **kwargs) File
"/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/backends/backend_qt5agg.py",
line 196, in print_figure FigureCanvasAgg.print_figure(self, *args, **kwargs)
File
"/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/backend_bases.py",
line 2232, in print_figure **kwargs) File
"/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/backends/backend_agg.py",
line 527, in print_png FigureCanvasAgg.draw(self) File
"/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/backends/backend_agg.py",
line 474, in draw self.figure.draw(self.renderer) File
"/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/artist.py",
line 61, in draw_wrapper draw(artist, renderer, *args, **kwargs) File
"/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/figure.py",
line 1159, in draw func(*args) File
"/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/artist.py",
line 61, in draw_wrapper draw(artist, renderer, *args, **kwargs) File
"/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/axes/_base.py",
line 2324, in draw a.draw(renderer) File
"/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/artist.py",
line 61, in draw_wrapper draw(artist, renderer, *args, **kwargs) File
"/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/text.py",
line 757, in draw raise ValueError("posx and posy should be finite values")
ValueError: posx and posy should be finite values

During handling of the above exception, another exception occurred:

Traceback (most recent call last): File "run_the_machine.py", line 404, in
<module> nwhiten_max=10, nwhiten_min=1, rms_floor=5e-4) File
"run_the_machine.py", line 149, in recov str(keplerid))) NameError: name
'keplerid' is not defined

* check why output depths are still negative (even post-correction... this is
likely something in the postprocessing? (else it's that I actually do need to
redo all my injection/recovery runs)
  > ya, it's fine for real_search. Just the output from injection/recovery is
  before I made this change.

* bugfix control flow when whitened 6row plot err

* write an analog of this that summarizes result from realsearch. (in
run_the_machine) irra.summarize_realsearch_result(). (Now using pf_SNR)

* Um. The Jenkins matched-filter approach is VERY DIFFERENT on the surface from
e.g., BLS. Are they equivalent? Which is better?  

>  Ya, it is. Chelsea Huang nominally ran a comparison back in 2012 (see Xu
Huang et al ApJ with the HAT group). The result is that BLS is a bit more
complete at short periods, for medium sized things. But the Kepler pipeline
does better at longer periods with smaller things. This means it might be a
good idea to look closely at the Kepler pipeline's methods, at least when
processing Kepler data!

Fri 31 Mar 2017 08:45:28 AM EDT

* Filter sorted results by isclose to multiples of P_rec_by_P_EB

* debug:

(sci) luke@crispy:~/Dropbox/proj/cbp/src$ WARNING: File may have been truncated: actual file length (49152) is smaller than the expected size (440640) [astropy.io.fits.file]
Traceback (most recent call last):
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/astropy/utils/decorators.py", line 496, in __get__
    return obj.__dict__[self._key]
KeyError: 'data'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "run_the_machine.py", line 407, in <module>
    nwhiten_max=10, nwhiten_min=1, rms_floor=5e-4)
  File "run_the_machine.py", line 76, in recov
    blacklist=blacklist)
  File "/home/luke/Dropbox/proj/cbp/src/inj_recov.py", line 473, in retrieve_next_lc
    rd, errflag = get_all_quarters_lc_data(this_id)
  File "/home/luke/Dropbox/proj/cbp/src/inj_recov.py", line 530, in get_all_quarters_lc_data
    lcd = astrokep.read_kepler_fitslc(fits_path)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/astrobase-0.1.0-py3.5.egg/astrobase/astrokep.py", line 226, in read_kepler_fitslc
    lchdr, lcdata = hdulist[1].header, hdulist[1].data
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/astropy/utils/decorators.py", line 498, in __get__
    val = self.fget(obj)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/astropy/io/fits/hdu/table.py", line 404, in data
    data = self._get_tbdata()
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/astropy/io/fits/hdu/table.py", line 171, in _get_tbdata
    self._data_offset)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/astropy/io/fits/hdu/base.py", line 568, in _get_raw_data
    return self._file.readarray(offset=offset, dtype=code, shape=shape)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/astropy/io/fits/file.py", line 283, in readarray
    buffer=self._mmap)
TypeError: buffer is too small for requested array
(sci) luke@crispy:~/Dropbox/proj/cbp/src$ 
[1]+  Exit 1                  python run_the_machine.py -frd > LOGS/findrealdips_170327_6.txt


* Discuss difference btwn things doing things the right way vs hacks with APW.
The basic take-away is that you need to do things in line with your goals.
E.g., if you just want to discover things, with statistical precision on the
back-burner, yes, something like sigmaclipping is OK.  But if you want to do
population inference on CBP occurrence rate about short-period binaries, you
need (at the very minimum) to understand your completeness. However doing so is
tricky -- you need to know that your injected signals are truly what you would
see. You might also need to debias your sample in other ways -- that was a
major idea in Armstrong's approach. (It is also why reading his THESIS, which
is presumably more verbose than the paper, could be worthwhile)

* Read Armstrong's _thesis_, b/c it might have more info than the paper (e.g.,
about sample selection, and short period binaries, and reasons for specific
methods, and whether he thinks he was complete for short-period binaries)

Sat 01 Apr 2017 05:50:47 PM EDT

Targetted reading:

* What parameters of the contact EBs must be known to make an inference about a
putative population of CBPs about them? 
(read DFM's code & the long period planet paper math)
> notes are written out; 170401_detection_efficiency_OOM.pdf

* Redefined motivation: if 10% of stars in short-period EB sample had Rp>4Re,
P_CPB=1-200d planets, we'd detect (Q_geom=0.1,Q_completeness=0.5)
1500*0.1*0.1*0.5 = 7.5 of em. If the Q_geom and Q_completeness estimates are
good, detecting <1 of them would mean an occurrence ~<3%(?) per star in the
short-period EB sample (in Rp=4-10Re vol, P_CBP=1-200d). (N.b. the (?) is
because Poisson statistics are the relevant thing there.) In other words, also
significantly lower than the standard star rate.  This result is an empirical
extension of Armstrong et al (2014)'s work on semi-detached and detached
binaries, into the contact binary regime. It is not surprising (if indeed the
search gives a null result): the majority (e.g., Tokovinin+ 2008) of contact
binaries have tertiary companions, and the very fact of being a contact binary
may preclude stability of CBPs during migration, at least in regimes observable
by transit surveys (the 3 recent theory papers, + Wenrui Xu's evection
resonance stuff).

* What parameters are actually known?  
(read Armstrong 2013 catalog paper; see how much he trusts the contact binary
parameters, and why) 
(read Ch 6 of Hilditch (emph on Ch6.4))
> notes are in lib/summarized_papers.txt

* What parameters can be estimated? (read the Rucinski papers, most notably
2006 Luminosity function, 2001 amplitude and mass ratio distributions, and
~2012 DDO Close Binary Spectroscopic Program)
> notes are in lib/summarized_papers.txt


##############################
##############################

Mon 03 Apr 2017 09:53:00 PM EDT

* make easiest disk space improvements. are we massively copying big things?
does each pkl need ~30Mb?
> Well, those with many iterations had ~100Mb. I implemented something to
drop the intermediate periodograms (the ones that i never look at) (although
this means backwards incompatibility w/ the 3row diagnostic)

> At 30Mb/ea, ~1600 LCs means main run produces 48Gb of data.
That's FINE. (Even at ~60Mb/ea, accounting for allq, 100Gb is ok).

> For injection recovery, we actually need far less data for production level
runs. Namely, we just need the planet and stars params and whether the injected
dip was found. So we can do ~20k inj/recovs, and keep maybe the first ~50
pickles or something like that. (As sanity checks). We could also only produce
plots for those 50. After that, proceed by just keeping track of some waaaay
lighter-weight thing.

This is OFC risky b/c if there's a mistake in the information that is saved
(like "oh hey, I actually wanted all those inj/recov periodograms!") then it
all needs to be recomputed. However for the number of inj/recovs we're talking
about, we just cannot store the full periodograms, and similarly there is not
much point in holding onto the full LC. (Obv different for the real search).


Tue 04 Apr 2017 05:17:19 PM EDT

Easiest speed improvements:
* do not make diagnostic plots until after pf-SNR is computed. If it's <3, we
  will not look at the LC, so do not make the plots.

*debug:
(sci) luke@crispy:~/Dropbox/proj/cbp/src$ Traceback (most recent call last):
  File "run_the_machine.py", line 407, in <module>
    lcd = get_lcd(stage='dtr', inj=False)
  File "run_the_machine.py", line 93, in recov
    if 'realsearch' in stage:
  File "/home/luke/Dropbox/proj/cbp/src/inj_recov.py", line 651, in detrend_allquarters
    inj=inj)
  File "/home/luke/Dropbox/proj/cbp/src/inj_recov.py", line 747, in detrend_lightcurve
    sel = (tgtimes > npmin(tgtimes)+mingap) & \
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/numpy/core/fromnumeric.py", line 2359, in amin
    out=out, keepdims=keepdims)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/numpy/core/_methods.py", line 29, in _amin
    return umr_minimum(a, axis, None, out, keepdims)
ValueError: zero-size array to reduction operation minimum which has no identity

* v1.0 tag



1. Be efficient with how you allocate your coding time.

Corollary: IGNORE your output for the toy run of 500 LCs, until you are ready
to look at it carefully, and in a way that allows u to update human-input
(e.g., y/n/maybe), one-time-thru. This human-input is only necessary once the
processing has been completed across everything, which means it's more
important to do the below things:


BEFORE PRODUCTION-LEVEL REAL SEARCH

x get a functioning software environment on adroit


X branch when beginning the adroit setup

ADROIT MOVE 
X where do we put the pkls? (it's just 100Gb!)
-> for now, just do it in same ../data/injrecov_pkl/real

X how do we define the array of jobs?
-> need to modify run_the_machine's recov (and perhaps inj) to accept KIC
ids. then feed them in as an index.

N.B. this is EXACTLY why it makes sense to branch. The PICSCIE setup for
running this code is different: it's "I would like to run many stars at the
same time across different cores".
The best way to avoid cross-talk is to specify which star you want in the
arguments (and skip over intermediates).

Can add this as two new cmd-line arguments: "-frd -cluster -kic [KICID]".
The addition to the codebase can then also be merged.


X make easiest speed improvements (e.g., profile with python -m cProfiler)
(currently, runs ~5 per hour. That gives 12.5 days to do the full 1500 LC
dataset. It gives >1 month to run the injection recovery sims, which is
untenable.).

These include:
X enable "multithread" over stars (this is the point of running on adroit).
  adroit has 160 cores, over 8 nodes (20 per node). my computer has 16.
  
  If we give each star e.g., 5 cores, (or even, say, 2), and can have >20 nodes
  running at a time, we are net winning. (Nb. we can easily get more cores by
  asking Jim, and quickly moving to a different cluster once we're on adroit)

Be efficient with how you allocate your coding time.

Corollary: IGNORE your output for the toy run of 500 LCs, until you are ready
to look at it carefully, and in a way that allows u to update human-input
(e.g., y/n/maybe), one-time-thru. This human-input is only necessary once the
processing has been completed across everything, which means it's more
important to do the below things:

* production run on actual KEBC stars, now that completeness is high enough,
and everything works fast enough.  ->  _look through_ the ~1.5k search results,
sorted per the above.
(my toy run of ~500 LCs on the desktop is not sustainable)

* bugfix:

Traceback (most recent call last):
  File "run_inj_recov.py", line 513, in <module>
    injrecov_test1(101, stage='dipsearch', inj=True, ds=True, whitened=True)
  File "run_inj_recov.py", line 480, in injrecov_test1
    irp.whitenedplot_6row(lcd, ap='sap', stage=stage, inj=inj)
  File "/home/luke/Dropbox/proj/cbp/src/inj_recov_plots.py", line 631, in whitenedplot_6row
    f.savefig(savedir+plotname, dpi=300)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/figure.py", line 1565, in savefig
    self.canvas.print_figure(*args, **kwargs)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/backends/backend_qt5agg.py", line 196, in print_figure
    FigureCanvasAgg.print_figure(self, *args, **kwargs)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/backend_bases.py", line 2232, in print_figure
    **kwargs)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/backends/backend_agg.py", line 527, in print_png
    FigureCanvasAgg.draw(self)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/backends/backend_agg.py", line 474, in draw
    self.figure.draw(self.renderer)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/artist.py", line 61, in draw_wrapper
    draw(artist, renderer, *args, **kwargs)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/figure.py", line 1159, in draw
    func(*args)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/artist.py", line 61, in draw_wrapper
    draw(artist, renderer, *args, **kwargs)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/axes/_base.py", line 2324, in draw
    a.draw(renderer)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/artist.py", line 61, in draw_wrapper
    draw(artist, renderer, *args, **kwargs)
  File "/home/luke/Dropbox/miniconda3/envs/sci/lib/python3.5/site-packages/matplotlib/text.py", line 757, in draw
    raise ValueError("posx and posy should be finite values")
ValueError: posx and posy should be finite values

[1]+  Exit 1                  python run_inj_recov.py > LOGS/completeness_test_170320_2.txt


* make ur interp1d calls smarter (if possible)

(NEVER DID)
* implement Armstrong+ 2014, Sec 3.1. Box with local polynomial detrending
  (add it in astrobase, then call in find_dips)


* check della legit works
> by just fixing my shit and doing it via injrecov.
> it can run 140 cores simultaneously on the short queue. At 1hr per injrecov
(BCS), we have 20k CPU hours to go thru. 140 CPUs means 1 real hour = 140 CPU
hours, so 2e4/140/24 = 6 days.
If they were willing to up the MaxJobsPerUser, to say 256 on this queue (to
match the MaxCPUsPerUser), this would shrink by a factor of 1.8 to 3.3 days.


lbouma@della4:~/proj/cbp$ qos
      Name   Priority GrpNodes  GrpCPUs MaxCPUsPU MaxJobsPU MaxNodesPU MaxSubmit 
---------- ---------- -------- -------- --------- --------- ---------- --------- 
     vlong       2800              1600       160        40                 2000 
    medium       3000              1600       256       140                 2000 
     short       5000                         256       140                 2000 
      test       6000                                     2                  200 


Wed 12 Apr 2017 11:31:58 AM EDT

* how do u classify btwn pulsators & EBs? (seems like the KEBWG had issues)
  > amplitude
  > shape (e.g. ellipsoidal variables, ELVs, vs γ Dor, vs low sini contact EB
  tend to have slightly differetn shapes. ELVs are sharp, no primary/secondary
  transit. Ditto γ Dor? A tell for γ Dor is star's Teff, logg, likely inferred
  thru colors)
X understand what "morph" means (Matijevic+ 2012).
  > see discussion in summarized_papers.txt
* ctrl-f thru Kepler EB WG papers for "pulsator" or "δ Sct" or (most
  relevant) "γ Dor" to see if they thought about these as false positives
  > doesn't matter so much if they did, they should have.
X based e.g. off Fig 4 of Matijevic+ 2012, or using the v2 hand classifications
  and cross-matching, what fraction of our morph>0.7 objects are contact binaries
  vs the other high-morphology classes?
  > like, half. (~58%, going off v2 of KEBC). see 170412_* in docs.

* Email Andrej with notes from search

  11013201:
  (Almost certain) the KEBC period is wrong. The period they give is a
  pulsation period (cf. Uytterhoeven+ (2011) and Niemczura+ (2015)). It should be a single 

  7515679:
  What do "Pu" flag mean? Not described in Kirk+ (2013). 
  > have examples to back up claim that they're contaminated.
  > e.g. crossmatch the 2011 Kepler astroseis paper
  Should Gamma dor be more incoherent? 

* Look at CFOP. Get account, query KOI, discussion.

* deep-dive into the literature for every candidate on your
list. Also, produce more narrow diagnostics (e.g., trimming out weird jumps,
dropping bad quarters, etc). Do they get better? Worse? What is known?

Uytterhoeven et al (2011):
** Table 3 & Table 4: KIC ID and classifications (for γ Dor vs δ Sct vs
hybrid). 
** Table 1 has ~750 candidate γ Dor and δ Sct pulsators.

* further analysis of remaining 4 (deep dive) (e.g.: by end of Thurs, have a
better idea which of the 4 seem promising / worth getting spectroscopy of).
  X Literature
  X CFOP
  X Exoplanet archive
  X Contamination fraction
  * Centroid motion: specific to dips.
    -> Look at vector difference associated w/ moments in time (in dips and
      outside). N.b. centroid time
    Read: Steve Bryson.
  X Better detrending / masking (cleanest possible look at signal). Careful f(t)
    timeseries.
  * **Odd/even** (key!)
  X Timing analysis of the dips: do we get nonperiodicites? -> does it hold w/ planet hypothesis?
  * Transit shape check: tricky b/c we don't expect it to be normal shaped. But if
    its excessively V-shaped.
  X Contamination factors from KIC indicate risk of light contamination from
  neighboring stars

* how do you determine W vs A type contact binaries? can it be done through
the LC alone? (important for estimating contamination fraction within things
hand-labelled as overcontact EBs)
-> from LC, can use periods and colors as an indicator.


email Andrej Prsa once you have questions he can help you understand


Sun 11 Jun 2017 12:17:46 PM EDT


X further analysis of remaining 4 (deep dive) (e.g.: by end of Thurs, have a
better idea which of the 4 seem promising / worth getting spectroscopy of).
  X Literature
  X CFOP
  X Exoplanet archive
  X Contamination fraction
  * Centroid motion: specific to dips.
    -> Look at vector difference associated w/ moments in time (in dips and
      outside). N.b. centroid time
    Read: Steve Bryson.
    -> read it, and that stuff is overkill for 2 objects. It takes serious
    treatment (read ~>two weeks of coding work+ analysis, at least) for basically
    anything like "conclusive" to come out. Look instead at Sanchis-Ojeda 2014.
    We can estimate, using simple physical arguments, the expected deviation that
    we might see in the centroid.
    It makes more sense to just take the centroid timeseries, convert to
    degrees in arcsec, do the full subtraction & keep it in relative units.

  X Simple physical arguments: are the transit durations good? (i.e. in line with 
  X Better detrending / masking (cleanest possible look at signal). Careful f(t)
    timeseries.
  X **Odd/even** (key!)
  X Timing analysis of the dips: do we get nonperiodicites? -> does it hold w/ planet hypothesis?
  X Transit shape check: tricky b/c we don't expect it to be normal shaped. But if
    its excessively V-shaped.
  X Contamination factors from KIC indicate risk of light contamination from
  neighboring stars


X begin paper draft (e.g., introduction, write up methods...)

~ ondrej peycha's ampltitude of variability idea.  

~ figure out photometric / spectroscopic / high angular resoln follow-up program

~```

Armstrong+ (2013): Best game in town(?) for KEBC temperatures.
* Compare performance w/ known systems (e.g. vs Armstrong+ 2013's Table 5)

Why do we care about the stellar properties?
1. We need to estimate our contamination fraction in the ~1k K"EB"C sample
2. If we want to convert our search result into Γ_V vs κ, we need to know the
inclinations of the systems, and the stellar radii (assuming Γ_V is defined
over planet radius, not δ).

The KEBC produced rough values of sini, R2/R1, T2/T1, which they then
retracted. Armstrong produced rough Teffs.
```

PAPER

X copy template from e.g. DFM (duh)
X write introduction

READING
X read Mowlavi et al recent Gaia EB gaussian fitting discussion. Could apply to
HAT data. What did they learn?  http://arxiv.org/abs/1703.10597
(also, read his other papers)

X why does that one KOI show up as a δ scuti? (was this a failure in the KEBC
pipeline?). How many of these instances are there?

X read WASP 33 Van Esse+ COROT paper. δ scuti w/ a transiting planet.  >
spatially-resolved light from transiting planet. Can you get e.g., obliquity of
star? (if you understand the pulsation dirns, you get a preferred dirn). Can u
understand the pulsations better by getting spatially- resolved light?

X look at DFM's new O(N) GP models. Can they be used for *discovery*, as is the
idea here?

X Rucinski 2004: how do you confirm that a variable star is a contact EB, not a
delta scuti or gamma doradus? 

X Why should a M_V(logP) calibration EXIST / work? 
Discussed in any of: Rucisnki 1994, Rucisnki & Duerbeck 1997, Rucinski 2004

[total aside question]:
X What aspects of stellar formation (or post-formation physical evolution) can
be inferred from contact EBs? Do they trace any particular physical processes?

~ avoid fitting out subharmonics of planet transits!!
Example cases: 8122124. See 8122124_qnum9_inum2_sap.png
Possibilities: 
- model comparison?
- smart condition on really only searching for harmonics & subharmonics 
  of EB signal (i.e. look over some frequency comb)
- nb. this really should only be an issue w/ the shortest-period injected 
  planets

~ review doc/discussion from 170308. consider integrating QATS (if we want 
  long-period, ED rather than just EC and EA sensitivity)

~ Understand how DFM+ peerless implemented model comparison once you have nice
    transits. Implement it.

~ How to fit out spots: e.g., with `george` (GP regression)?

Longer-term ideas:
~Detrend+normalize:
    Match the KEBC detrending? As-is, I think I'm leaving in trends that are
    too big.

~ add "s2n_on_grass" (Petigura et al 2013) to cull out "significant" transits
-> can do this in post-processing, or (likely better) add direct to
astrobase. See FIXME below.

 ALSO:
astrokep.stitch_lightcurve_gaps

astrokep.keplerflux_to_keplermag

ALSO:
 PyKE is also worth assessing: what detrending tricks does it use?

X production run on actual KEBC stars, now that completeness is high enough,
and everything works fast enough.  ->  _look through_ the ~1.5k search results,
sorted per the above.
(my toy run of ~500 LCs on the desktop is not sustainable)


X how big & how fine of an injection grid do we need/want to answer the
_statistical_ questions (on occurrence rates) --> see
../../peerless/peerless/occurrence.py for an example of the actual calculation
that's required

> yes, it must be a big grid.


METHOD THINGS

X redownload KEBC v3
  X ack-grep to find all instances of "kepler_eb_catalog_v3.csv" in code
    (ack-grep -l for file names only), `vi -p` to open many of them at once,
    and then find-replace across all of them for kebc_v3_170611.csv
  X update paper text

x select P less than 3 day objects from KEBC too (as described in text)

X actually compute lightcurve RMS where u say u do in pseudo-code

X change ir.find-dips' smallfactor to be 2 (Li, Holman, Tao 2016 misaligned), 

X keep max period as 150 days

X same in periodograms (PDM search part...)

X set the minimum transit duration in phase to be less than 0.005.
  For a 30 day period, that's 3.6hr; for a 50 day period it's 6 hr.
  So ~half that minimum phase would have been better...
  > done -- letting it be 0.0025

X regenerate (in appropriate ``plot'' folder of the paper) the legendre degree 
vs n points plots for Fig.~\ref{fig:legdeg_vs_npts_fluxvsphase} and 
Fig.~\ref{fig:legdeg_vs_npts_fluxvstime}

Mon 12 Jun 2017 12:27:10 PM EDT

X in find_dips, store the depths for the depths ur keeping, so that in
phase-folded LCs you can OVERPLOT the BLS model (um, duh?)

X in phase-folded LC plots, overplot the BLS model
  X code it in
  X begin testing
  X finish testing

  ~ debug why the durations of detected BLS dips are too short (as in the
    single case you currently have...)
  -> they are short, but I think it's a factor of 2 error, and it does not
  affect the overplotted BLS models (for some magical reason).
  Both 5302006 and 11013201 look fine. So we can say the overplotting works.

X debug aastex6 table for injected parameter draws.

X am I injecting the right eccentricties?
  > ya. (although kipping's values were from 

X why does table have two rows for eccentricity?

X correct the injected parameters with what i'm actually using. 

X fix the 2pi in ur precession timescale contours (paper)

X sanity check that the actual plot gives numbers that agree with the analytics
(it does, for the x=5, P=1day case)

X add completeness map generation script (not just the pdf) to /paper/figures

X
in injection recovery, is my procedure for drawing impact parameters
reasonable? or is it too weirdly biased, and should I be actually trying to do
something better for R_star and M_star?

X inject_transit_known_depth bug fix:
qinjsapflux = qsapflux + (qfluxtoinj-1.)*np.nanmedian(qsapflux)

pretty sure this is the wrong procedure. qsapflux is in ADU.
you want to... i THINK... just multiply qfluxtoinj (relative flux units) by
qsapflux. b/c if the entire star "gets brighter" (or really, there's some
instrumental brightening systematic)... i think you'd expect the transit depths
to scale commensurately. 

--> this fixes the claim in your description of inj/recov that you're
multiplying in the signals.
(Following DFM peerless, p. 15: "the transit signal is computed and MULTIPLIED
into the PDC LC")

Wed 14 Jun 2017 12:44:22 PM EDT

No. Discussed w/ JNW. The idea here is that we have a blob of fixed intensity
whose angular size is changing. So the diminishment reduction is always
CONSTANT, and should be subtracted (not multiplied in).

This is the converse case from a blob of fixed angular size whose intensity is
changing. This latter case would be multiplied in. 

So the median is OK.

For injection: could then opt to only sample across (P, δ, Tdur). We do not
know enough about the stars to be sampling over actual physical models (do not
fool yourself).  -> can go pretty fine for sampling, and then build a lookup
table. Any physical interpretation for a proposed planet population comes from
the lookup table after.

However, this lookup table can also be constructed just as well from using
batman (which is also easier, and pretty much as fast as whatever homebrew
thing I would cook up).

At the end of the day, either method requires sampling over the stellar density
(in order to get Tdur for JNW's proposed method, in order to get a by Rstar and
b in mine). Might as well opt for more parameters, to squash any idea that
they're being slipped under the rug + to not have to rewrite a kepler cadence
convolver
